{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data acquisition and extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key aspects for effective scraping are **understanding how content and data are stored on web servers, identifying the data you want to retrieve, and understanding how thetools support this extraction**. We will discuss website structures and the DOM, introduce techniques to parse, and query websites with lxml, XPath, and CSS. We will also look at how to work with websites developed in other languages and different encoding types such as Unicode.\n",
    "\n",
    "Ultimately, understanding how to find and extract data within an HTML document comes down to understanding the structure of the HTML page, its representation in the DOM, the process of querying the DOM for specific elements, and how to specify which elements you want to retrieve based upon how the data is represented."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **How to parse websites and navigate the DOM using BeautifulSoup**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the browser displays a web page it builds a model of the content of the page in a representation knows as the **document object model (DOM)**. The DOM is a hierarchical representation of the page's entire content, as well as structural information, style information, scripts, and links to other content.\n",
    "\n",
    "It is critical to understand this structure to be ablse to effectively scrape data from web pages. We will look at an example web page, its DOM and examine how to navigate the DOM with Beatiful Soup."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Getting ready**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a small web site that is included in the `www` folder of the sample code.  To follow along, start a web server from within the `www` folder.  This can be done with Python 3 as follows:\n",
    "\n",
    "```bash\n",
    "ww $ python3 -m http.server 8080\n",
    "Serving HTTP on 0.0.0.0 port 8080 (http://0.0.0.0:8080/)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DOM of a web page can be examined in Chrome by right-clicking the page and selecting Inspect. This opens the Chrome Developer Tools. Open a browser page to `http://localhost:8080/planets.html`. Within chrome you can right click and select 'inspect' to open developer tools (other browsers have similar tools).\n",
    "\n",
    "This opens the developer tools and the inspector. The DOM can be examined in the Elements tab.\n",
    "\n",
    "The following shows the selection of the first row in the table.\n",
    "ach row of planets is within a `<tr>` element.  There are several characteristics of this element and its neighboring elements that we will examine because they are designed to model common web pages.\n",
    "\n",
    "Firstly, this element has three attributes: `id`, `planet`, and `name`. Attributes are often important in scraping as they are commonly used to identify and locate data embedded in the HTML.\n",
    "\n",
    "Secondly, the `<tr>` element has children, and in this case, five `<td>` elements. We will often need to look into the children of a specific element to find the actual data that is desired.\n",
    "\n",
    "This element also has a parent element, `<tbody>`. There are also sibling elements, and the a set of `<tr>`  child elements.  From any planet, we can go up to the parent and find the other planets. And as we will see, we can use various constructs in the various tools, such as the `find` family of functions in Beautiful Soup, and also `XPath` queries, to easily navigate these relationships.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to do it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n<head>\\n</head>\\n<body>\\n<div id=\"planets\">\\n<h1>Planetary data</h1>\\n<div id=\"content\">Here are some interesting facts about the planets in our solar system</div>\\n<p></p>\\n<table border=\"1\" id=\"planetsTable\">\\n<tr id=\"planetHeader\">\\n<th>\\n</th>\\n<th>\\n                    Name\\n                </th>\\n<th>\\n                    Mass (10^24kg)\\n                </th>\\n<th>\\n                    Diameter (km)\\n                </th>\\n<th>\\n                    How it got its Name\\n                </th>\\n<th>\\n                    More Info\\n                </th>\\n</tr>\\n<tr class=\"planet\" id=\"planet1\" name=\"Mercury\">\\n<td>\\n<img src=\"img/mercury-150x150.png\"/>\\n</td>\\n<td>\\n                    Mercury\\n                </td>\\n<td>\\n                    0.330\\n                </td>\\n<td>\\n                    4879\\n                </td>\\n<td>Named Mercurius by the Romans because it appears to move so swiftly.</td>\\n<td>\\n<a href=\"https://en.wikipedia.org/wiki/Mercury_(planet)\">Wikipedia</a>\\n</td>\\n</tr>\\n<tr class=\"planet\" id=\"plane'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "html = requests.get(\"http://localhost:8080/planets.html\").text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "str(soup)[:1000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can navigate the elements in the DOM using properties of soup. soup represents the overall document and we can drill into the document by chaining the tag names. The following navigates to the `<table>` containing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" id=\"planetsTable\">\\n<tr id=\"planetHeader\">\\n<th>\\n</th>\\n<th>\\n                    Name\\n                </th>\\n<th>\\n                    Mass (10^24kg)\\n                </th>\\n<th>\\n          '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(soup.html.body.div.table)[:200]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this type of notation retrieves only the first child of that type.  Finding more requires iterations of all the children, which we will do next, or using the find methods (the next recipe).\n",
    "\n",
    "**Each node has both children and descendants**. Descendants are all the nodes underneath a given node (event at further levels than the immediate children), while children are those that are a first level descendant. The following retrieves the children of the table, which is actually a `list_iterator` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x7f8fbb527fa0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.html.body.div.table.children"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine each child element in the iterator using a for loop or a Python generator. The following uses a generator to get all the children of the and return the first few characters of their constituent HTML as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " '<tr id=\"planetHeader\">\\n<th>\\n</th>\\n<th>\\n      ',\n",
       " '\\n',\n",
       " '<tr class=\"planet\" id=\"planet1\" name=\"Mercury',\n",
       " '\\n',\n",
       " '<tr class=\"planet\" id=\"planet2\" name=\"Venus\">',\n",
       " '\\n',\n",
       " '<tr class=\"planet\" id=\"planet3\" name=\"Earth\">',\n",
       " '\\n',\n",
       " '<tr class=\"planet\" id=\"planet4\" name=\"Mars\">\\n',\n",
       " '\\n',\n",
       " '<tr class=\"planet\" id=\"planet5\" name=\"Jupiter',\n",
       " '\\n',\n",
       " '<tr class=\"planet\" id=\"planet6\" name=\"Saturn\"',\n",
       " '\\n',\n",
       " '<tr class=\"planet\" id=\"planet7\" name=\"Uranus\"',\n",
       " '\\n',\n",
       " '<tr class=\"planet\" id=\"planet8\" name=\"Neptune',\n",
       " '\\n',\n",
       " '<tr class=\"planet\" id=\"planet9\" name=\"Pluto\">',\n",
       " '\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(c)[:45] for c in soup.html.body.div.table.children]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, the parent of a node can be found using the `.parent` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" id=\"planetsTable\">\\n<tr id=\"planetHeader\">\\n<th>\\n</th>\\n<th>\\n                    Name\\n                </th>\\n<th>\\n                    Mass (10^24kg)\\n                </th>\\n<th>\\n          '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(soup.html.body.div.table.tr.parent)[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How it works**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup converts the HTML from the page into its own internal representation. This model has an identical representation to the DOM that would be created by a browser. But Beautiful Soup also provides many powerful capabilities for navigating the elements in the DOM, such as what we have seen when using the tag names as properties.  These are great for finding things when we know a fixed path through the HTML with the tag names."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **There's more**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This manner of navigating the DOM is relatively inflexible and is highly dependent upon the structure**. It is possible that this structure can change over time as web pages are updated by their creator(s). The pages could even look identical, but have a completely different structure that breaks your scraping code.\n",
    "\n",
    "So how can we deal with this? As we will see, **there are several ways of searching for elements that are much better than defining explicit paths**. In general, **we can do this using XPath and by using the find methods of beautiful soup**. We will examine both in recipes later in this chapter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Searching the DOM with Beautiful Soup's find methods**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform simple searches of the DOM using Beautiful Soup's find methods. These methods give us a much more flexible and powerful construct for finding elements that are not dependent upon the hierarchy of those elements.  In this recipe we will examine  several common uses of these functions to locate various elements in the DOM."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to do it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" id=\"planetsTable\">\\n<tr id=\"planetHeader\">\\n<th>\\n</th>\\n<th>\\n                    Name'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "html = requests.get('http://localhost:8080/planets.html').text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "table = soup.find('table')\n",
    "str(table)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<tr id=\"planetHeader\">\\n<th>\\n</th>\\n<th>\\n           ',\n",
       " '<tr class=\"planet\" id=\"planet1\" name=\"Mercury\">\\n<t',\n",
       " '<tr class=\"planet\" id=\"planet2\" name=\"Venus\">\\n<td>',\n",
       " '<tr class=\"planet\" id=\"planet3\" name=\"Earth\">\\n<td>',\n",
       " '<tr class=\"planet\" id=\"planet4\" name=\"Mars\">\\n<td>\\n',\n",
       " '<tr class=\"planet\" id=\"planet5\" name=\"Jupiter\">\\n<t',\n",
       " '<tr class=\"planet\" id=\"planet6\" name=\"Saturn\">\\n<td',\n",
       " '<tr class=\"planet\" id=\"planet7\" name=\"Uranus\">\\n<td',\n",
       " '<tr class=\"planet\" id=\"planet8\" name=\"Neptune\">\\n<t',\n",
       " '<tr class=\"planet\" id=\"planet9\" name=\"Pluto\">\\n<td>']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(tr)[:50] for tr in table.findAll(\"tr\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that these are the descendants and not immediate children.  Change the query to \"td\" to see the difference.  The are no direct children that are `<td>`, but each row has multiple `<td>` elements.  In all, there would be $54$ `<td>` elements found.\n",
    "\n",
    "There is a small issue here if we want only rows that contain data for planets. The table header is also included.  We can fix this by utilizing the id attribute of the target rows.  The following finds the row where the value of `id` is `\"planet3\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr class=\"planet\" id=\"planet3\" name=\"Earth\">\n",
       "<td>\n",
       "<img src=\"img/earth-150x150.png\"/>\n",
       "</td>\n",
       "<td>\n",
       "                    Earth\n",
       "                </td>\n",
       "<td>\n",
       "                    5.97\n",
       "                </td>\n",
       "<td>\n",
       "                    12756\n",
       "                </td>\n",
       "<td>\n",
       "                    The name Earth comes from the Indo-European base 'er,'which produced the Germanic noun 'ertho,' and ultimately German 'erde,'\n",
       "                    Dutch 'aarde,' Scandinavian 'jord,' and English 'earth.' Related forms include Greek 'eraze,' meaning\n",
       "                    'on the ground,' and Welsh 'erw,' meaning 'a piece of land.'\n",
       "                </td>\n",
       "<td>\n",
       "<a href=\"https://en.wikipedia.org/wiki/Earth\">Wikipedia</a>\n",
       "</td>\n",
       "</tr>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.find(\"tr\", {\"id\": \"planet3\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We used the fact that this page uses this attribute to represent table rows with actual data.\n",
    "\n",
    "Now let's go one step further and collect the masses for each planet and put the name and mass in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mercury': '0.330',\n",
       " 'Venus': '4.87',\n",
       " 'Earth': '5.97',\n",
       " 'Mars': '0.642',\n",
       " 'Jupiter': '1898',\n",
       " 'Saturn': '568',\n",
       " 'Uranus': '86.8',\n",
       " 'Neptune': '102',\n",
       " 'Pluto': '0.0146'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = dict()\n",
    "planet_rows = table.findAll(\"tr\", {\"class\": \"planet\"})\n",
    "for i in planet_rows:\n",
    "    tds = i.findAll(\"td\")\n",
    "    items[tds[1].text.strip()] = tds[2].text.strip()\n",
    "\n",
    "items"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Querying the DOM with XPath and lxml**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XPath is a query language for selecting nodes from an XML document and is a must-learn query language for anyone performing web scraping. XPath offers a number of benefits to its user over other model-based tools:\n",
    "\n",
    "* Can easily navigate through the DOM tree\n",
    "* More sophisticated and powerful than other selectors like CSS selectors and regular expressions\n",
    "* It has a great set $(200+)$ of built-in functions and is extensible with custom functions\n",
    "* It is widely supported by parsing libraries and scraping platforms\n",
    "\n",
    "XPath contains seven data models (we have seen some of them previously):\n",
    "\n",
    "* root node (top level parent node)\n",
    "* element nodes (`<a>...</a>`)\n",
    "* attribute nodes (`href=\"example.html\"`)\n",
    "* text nodes (`\"this is a text\"`)\n",
    "* comment nodes (`<!-- a comment -->`)\n",
    "* namespace nodes \n",
    "* processing instruction nodes\n",
    "\n",
    "XPath expressions can return different data types:\n",
    "\n",
    "* strings\n",
    "* booleans\n",
    "* numbers\n",
    "* node-sets (probably the most common case)\n",
    "\n",
    "An (XPath) **`axis`** defines a node-set relative to the current node. A total of $13$ axes are defined in XPath to enable easy searching for different node parts, from the current context node, or the root node.\n",
    "\n",
    "**`lxml`** is a Python wrapper on top of the libxml2 XML parsing library, which is written in C. The implementation in C helps make it faster than Beautiful Soup, but also harder to install on some computers. The latest installation instructions are available [here](http://lxml.de/installation.html).\n",
    "\n",
    "lxml supports XPath, which makes it considerably easy to manage complex XML and HTML documents. We will examine several techniques of using lxml and XPath together, and how to use lxml and XPath to navigate the DOM and access data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Getting ready**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by importing html from lxml, as well as requests, and then load the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ibrahim/miniconda3/envs/scraping\n",
      "\n",
      "  added / updated specs:\n",
      "    - lxml\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    lxml-4.9.1                 |  py310h1edc446_0         6.1 MB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         6.1 MB\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2022.12.~ --> anaconda::ca-certificates-2022.07.19-h06a4308_0 \n",
      "  certifi            conda-forge/noarch::certifi-2022.12.7~ --> anaconda/linux-64::certifi-2022.6.15-py310h06a4308_0 \n",
      "  lxml                                            pkgs/main --> anaconda \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "                                                                                \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install -c anaconda lxml -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "page_html = requests.get(\"http://localhost:8080/planets.html\").text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to do it**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that we do is to load the HTML into an lxml `\"etree\"`.  This is lxml's representation of the DOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = html.fromstring(page_html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree variable is now an lxml representation of the DOM which models the HTML content. Let's now examine how to use it and XPath to select various elements from the document.\n",
    "\n",
    "Out first XPath example will be to find all the the `<tr>` elements below the `<table>` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element tr at 0x7ff20020dd50>,\n",
       " <Element tr at 0x7ff20020f290>,\n",
       " <Element tr at 0x7ff20020eb10>,\n",
       " <Element tr at 0x7ff20020f3d0>,\n",
       " <Element tr at 0x7ff20020e430>,\n",
       " <Element tr at 0x7ff20020ec00>,\n",
       " <Element tr at 0x7ff20020dfd0>,\n",
       " <Element tr at 0x7ff20020f1a0>,\n",
       " <Element tr at 0x7ff20020e750>,\n",
       " <Element tr at 0x7ff20020f010>,\n",
       " <Element tr at 0x7ff20020eed0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tr for tr in tree.xpath(\"/html/body/div/table/tr\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This XPath navigates by tag name from the root of the document down to the `<tr>` element.  This example looks similar to the property notation from Beautiful Soup, but ultimately it is significantly more expressive.  And notice one difference in the result.  All the the `<tr>` elements were returned and not just the first.  As a matter of fact, the tags at each level of this path with return multiple items if they are available.  If there was multiple `<div>` elements just below `<body>`, then the search for `table/tr` would be executed on all of those `<div>`.\n",
    "\n",
    "The actual result was an lxml element object.  The following gets the HTML associated with the elements but using `etree.tostring()` (albeit they have encoding applied):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<tr id=\"planetHeader\">\\n                <th>\\n      ',\n",
       " b'<tr id=\"planet1\" class=\"planet\" name=\"Mercury\">\\n  ',\n",
       " b'<tr id=\"planet2\" class=\"planet\" name=\"Venus\">\\n    ',\n",
       " b'<tr id=\"planet3\" class=\"planet\" name=\"Earth\">\\n    ',\n",
       " b'<tr id=\"planet4\" class=\"planet\" name=\"Mars\">\\n     ',\n",
       " b'<tr id=\"planet5\" class=\"planet\" name=\"Jupiter\">\\n  ',\n",
       " b'<tr id=\"planet6\" class=\"planet\" name=\"Saturn\">\\n   ',\n",
       " b'<tr id=\"planet7\" class=\"planet\" name=\"Uranus\">\\n   ',\n",
       " b'<tr id=\"planet8\" class=\"planet\" name=\"Neptune\">\\n  ',\n",
       " b'<tr id=\"planet9\" class=\"planet\" name=\"Pluto\">\\n    ',\n",
       " b'<tr id=\"footerRow\">\\n                <td>\\n         ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lxml import etree\n",
    "[etree.tostring(tr)[:50] for tr in tree.xpath(\"/html/body/div/table/tr\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at using XPath to select only the `<tr>` elements that are planets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<tr id=\"planet1\" class=\"planet\" name=\"Mercury\">\\n  ',\n",
       " b'<tr id=\"planet2\" class=\"planet\" name=\"Venus\">\\n    ',\n",
       " b'<tr id=\"planet3\" class=\"planet\" name=\"Earth\">\\n    ',\n",
       " b'<tr id=\"planet4\" class=\"planet\" name=\"Mars\">\\n     ',\n",
       " b'<tr id=\"planet5\" class=\"planet\" name=\"Jupiter\">\\n  ',\n",
       " b'<tr id=\"planet6\" class=\"planet\" name=\"Saturn\">\\n   ',\n",
       " b'<tr id=\"planet7\" class=\"planet\" name=\"Uranus\">\\n   ',\n",
       " b'<tr id=\"planet8\" class=\"planet\" name=\"Neptune\">\\n  ',\n",
       " b'<tr id=\"planet9\" class=\"planet\" name=\"Pluto\">\\n    ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[etree.tostring(tr)[:50] for tr in tree.xpath(\"/html/body/div/table/tr[@class='planet']\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of the `[]` next to a tag states that we want to do a selection based on some criteria upon the current element.  The @ states that we want to examine an attribute of the tag, and in this cast we want to select tags where the attribute is equal to `\"planet\"`.\n",
    "\n",
    "There is also another point to be made out of the query that had 11 `<tr> `rows.  As stated earlier, the XPath runs the navigation on all the nodes found at each level.  There are two tables in this document, both children of a different `<div>` that are both a child or the `<body>` element.  The row with `id=\"planetHeader`\" came from our desired target table, the other, with id=\"footerRow\", came from the second table.\n",
    "\n",
    "Previously we solved this by selecting `<tr>` with `class=\"row\"`, but there are also other ways worth a brief mention.  The first is that we can also use [] to specify a specific element at each section of the XPath like they are arrays.  Take the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<tr id=\"planetHeader\">\\n                <th>\\n      ',\n",
       " b'<tr id=\"planet1\" class=\"planet\" name=\"Mercury\">\\n  ',\n",
       " b'<tr id=\"planet2\" class=\"planet\" name=\"Venus\">\\n    ',\n",
       " b'<tr id=\"planet3\" class=\"planet\" name=\"Earth\">\\n    ',\n",
       " b'<tr id=\"planet4\" class=\"planet\" name=\"Mars\">\\n     ',\n",
       " b'<tr id=\"planet5\" class=\"planet\" name=\"Jupiter\">\\n  ',\n",
       " b'<tr id=\"planet6\" class=\"planet\" name=\"Saturn\">\\n   ',\n",
       " b'<tr id=\"planet7\" class=\"planet\" name=\"Uranus\">\\n   ',\n",
       " b'<tr id=\"planet8\" class=\"planet\" name=\"Neptune\">\\n  ',\n",
       " b'<tr id=\"planet9\" class=\"planet\" name=\"Pluto\">\\n    ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[etree.tostring(tr)[:50] for tr in tree.xpath(\"/html/body/div[1]/table/tr\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays in XPath start at 1 instead of 0 (a common source of error).  This selected the first `<div>`.  A change to `[2]` selects the second `<div>` and hence only the second `<table>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<table id=\"footerTable\">\\n            <tr id=\"foote']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[etree.tostring(tr)[:50] for tr in tree.xpath(\"/html/body/div/table/tr/parent::table[@id='footerTable']\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first <div> in this document also has an id attribute:\n",
    "```html\n",
    "<div id=\"planets\"> \n",
    "```\n",
    "This can be used to select this `<div>`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<tr id=\"planetHeader\">\\n                <th>\\n      ',\n",
       " b'<tr id=\"planet1\" class=\"planet\" name=\"Mercury\">\\n  ',\n",
       " b'<tr id=\"planet2\" class=\"planet\" name=\"Venus\">\\n    ',\n",
       " b'<tr id=\"planet3\" class=\"planet\" name=\"Earth\">\\n    ',\n",
       " b'<tr id=\"planet4\" class=\"planet\" name=\"Mars\">\\n     ',\n",
       " b'<tr id=\"planet5\" class=\"planet\" name=\"Jupiter\">\\n  ',\n",
       " b'<tr id=\"planet6\" class=\"planet\" name=\"Saturn\">\\n   ',\n",
       " b'<tr id=\"planet7\" class=\"planet\" name=\"Uranus\">\\n   ',\n",
       " b'<tr id=\"planet8\" class=\"planet\" name=\"Neptune\">\\n  ',\n",
       " b'<tr id=\"planet9\" class=\"planet\" name=\"Pluto\">\\n    ']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[etree.tostring(tr)[:50] for tr in tree.xpath(\"/html/body/div[@id='planets']/table/tr\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we selected the planet rows based upon the value of the class attribute.  We can also exclude rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<tr id=\"planet1\" class=\"planet\" name=\"Mercury\">\\n  ',\n",
       " b'<tr id=\"planet2\" class=\"planet\" name=\"Venus\">\\n    ',\n",
       " b'<tr id=\"planet3\" class=\"planet\" name=\"Earth\">\\n    ',\n",
       " b'<tr id=\"planet4\" class=\"planet\" name=\"Mars\">\\n     ',\n",
       " b'<tr id=\"planet5\" class=\"planet\" name=\"Jupiter\">\\n  ',\n",
       " b'<tr id=\"planet6\" class=\"planet\" name=\"Saturn\">\\n   ',\n",
       " b'<tr id=\"planet7\" class=\"planet\" name=\"Uranus\">\\n   ',\n",
       " b'<tr id=\"planet8\" class=\"planet\" name=\"Neptune\">\\n  ',\n",
       " b'<tr id=\"planet9\" class=\"planet\" name=\"Pluto\">\\n    ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[etree.tostring(tr)[:50] for tr in tree.xpath(\"/html/body/div[@id='planets']/table/tr[@id!='planetHeader']\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that the planet rows did not have attributes (nor the header row), then we could do this by position, skipping the first row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<tr id=\"planet1\" class=\"planet\" name=\"Mercury\">\\n  ',\n",
       " b'<tr id=\"planet2\" class=\"planet\" name=\"Venus\">\\n    ',\n",
       " b'<tr id=\"planet3\" class=\"planet\" name=\"Earth\">\\n    ',\n",
       " b'<tr id=\"planet4\" class=\"planet\" name=\"Mars\">\\n     ',\n",
       " b'<tr id=\"planet5\" class=\"planet\" name=\"Jupiter\">\\n  ',\n",
       " b'<tr id=\"planet6\" class=\"planet\" name=\"Saturn\">\\n   ',\n",
       " b'<tr id=\"planet7\" class=\"planet\" name=\"Uranus\">\\n   ',\n",
       " b'<tr id=\"planet8\" class=\"planet\" name=\"Neptune\">\\n  ',\n",
       " b'<tr id=\"planet9\" class=\"planet\" name=\"Pluto\">\\n    ']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[etree.tostring(tr)[:50] for tr in tree.xpath(\"/html/body/div[@id='planets']/table/tr[position() > 1]\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to navigate to the parent of a node using `parent::*`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<table id=\"planetsTable\" border=\"1\">\\n            <',\n",
       " b'<table id=\"footerTable\">\\n            <tr id=\"foote']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[etree.tostring(tr)[:50] for tr in tree.xpath(\"/html/body/div/table/tr/parent::*\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returned two parents as, remember, this XPath returns the rows from two tables, so the parents of all those rows are found. The `*` is a wild card that represents any parent tags with any name. In this case, the two parents are both tables, but in general the result can be any number of HTML element types.  The following has the same result, but if the two parents where different HTML tags then it would only return the `<table>` elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<table id=\"planetsTable\" border=\"1\">\\n            <',\n",
       " b'<table id=\"footerTable\">\\n            <tr id=\"foote']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[etree.tostring(tr)[:50] for tr in tree.xpath(\"/html/body/div/table/tr/parent::table\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to specify a specific parent by position or attribute. The following selects the parent with `id=\"footerTable\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<table id=\"footerTable\">\\n            <tr id=\"foote']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[etree.tostring(tr)[:50] for tr in tree.xpath(\"/html/body/div/table/tr/parent::table[@id='footerTable']\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A shortcut for parent is `..` (and `.` also represents the current node):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<table id=\"planetsTable\" border=\"1\">\\n            <',\n",
       " b'<table id=\"footerTable\">\\n            <tr id=\"foote']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[etree.tostring(tr)[:50] for tr in tree.xpath(\"/html/body/div/table/tr/..\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the last example finds the mass of Earth: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.97'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass = tree.xpath(\"/html/body/div[1]/table/tr[@name='Earth']/td[3]/text()[1]\")[0].strip()\n",
    "mass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trailing portion of this `XPath`, `/td[3]/text()[1]`, selects the $3^{rd}$ `<td>` element in the row, then the text of that element (which is an array of all the text in the element), and the $1^{st}$ of those which is the mass."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How it works**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`XPath` is a element of the **XSLT** (**eXtensible Stylesheet Language Transformation**) standard and provides the ability to select nodes in an XML document. HTML is a variant of XML, and hence XPath can work on on HTML document (although HTML can be improperly formed and mess up XPath parsing in those cases).\n",
    "\n",
    "XPath itself is designed to model the structure of XML nodes, attributes, and properties. The syntax provides means of finding items in the XML that match the expression. This can include matching or logical comparison of any of the nodes, attributes, values, or text in the XML document.\n",
    "\n",
    "> XPath expressions can be combined to form very complex paths within the document. It is also possible to navigate the document based upon relative positions, which helps greatly in finding data based upon relative positions instead of absolute positions within the DOM.\n",
    "\n",
    "Understanding XPath is essential for knowing how to parse HTML and perform web scraping. And as we will see, it underlies, and provides an implementation for, many of the higher level libraries such as lxml."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **There's more**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's more...\n",
    "XPath is actually an amazing tool for working with XML and HTML documents. It is quite rich in its capabilities, and we have barely touched the surface of its capabilities for demonstrating a few examples that are common to scraping data in HTML documents.\n",
    "\n",
    "To learn much more, please visit the following links:\n",
    "\n",
    "* [https://www.w3schools.com/xml/xml_xpath.asp](https://www.w3schools.com/xml/xml_xpath.asp)\n",
    "* [https://www.w3.org/TR/xpath/](https://www.w3.org/TR/xpath/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Querying data with XPath and CSS selectors**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSS selectors are patterns used for selecting elements and are often used to define the elements that styles should be applied to. They can also be used with lxml to select nodes in the DOM. CSS selectors are commonly used as they are more compact than XPath and generally can be more reusable in code. Examples of common selectors which may be used are as follows:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| What you are looking for                                    | Example      |\n",
    "| ----------------------------------------------------------- | ------------ |\n",
    "| All tags                                                    | `*`          |\n",
    "| A specific tag (that is, `tr`)                              | `.planet`    |\n",
    "| A class name (that is, `\"planet\"`)                          | `tr.planet`  |\n",
    "| A tag with an `ID` `\"planet3\"`                              | `tr#planet3` |\n",
    "| A child `tr` of a table                                     | `table tr`   |\n",
    "| A descendant `tr` of a table                                | `table tr`   |\n",
    "| A tag with an attribute (that is, `tr` with `id=\"planet4\"`) | `a[id=Mars]` |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Getting ready**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "\n",
    "page_html = requests.get(\"http://localhost:8080/planets.html\").text\n",
    "tree = html.fromstring(page_html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to do it**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start playing with XPath and CSS selectors.  The following selects all `<tr>` elements with a class equal to `\"planet\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<Element tr at 0x7ff20020eac0>, ['Mercury']),\n",
       " (<Element tr at 0x7ff1fd68bfb0>, ['Venus']),\n",
       " (<Element tr at 0x7ff1dd145580>, ['Earth']),\n",
       " (<Element tr at 0x7ff1dd145940>, ['Mars']),\n",
       " (<Element tr at 0x7ff1dd161760>, ['Jupiter']),\n",
       " (<Element tr at 0x7ff1dd161a30>, ['Saturn']),\n",
       " (<Element tr at 0x7ff1dd1636f0>, ['Uranus']),\n",
       " (<Element tr at 0x7ff1dd161da0>, ['Neptune']),\n",
       " (<Element tr at 0x7ff1dd163ec0>, ['Pluto'])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(v, v.xpath(\"@name\")) for v in tree.cssselect('tr.planet')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for the Earth can be found in several ways. The following gets the row based on id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Element tr at 0x7ff1dd145580>, 'Earth')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = tree.cssselect(\"tr#planet3\")\n",
    "tr[0], tr[0].xpath(\"./td[2]/text()\")[0].strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following uses an attribute with a specific value: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.cssselect(\"tr[name='Pluto']\")\n",
    "tr[0], tr[0].xpath(\"td[2]/text()\")[0].strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that unlike XPath, the `@` symbol need not be used to specify an attribute."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How it works**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lxml converts the CSS selector you provide to XPath, and then performs that XPath expression against the underlying document. In essence, CSS selectors in lxml provide a shorthand to XPath, which makes finding nodes that fit certain patterns simpler than with XPath."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **There's more**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because **CSS selectors utilize XPath under the covers, there is overhead to its use as compared to using XPath directly**. This difference is, however, almost a non-issue, and hence in certain scenarios it is easier to just use `cssselect`.\n",
    "\n",
    "A full description of CSS selectors can be found at: https://www.w3.org/TR/2011/REC-css3-selectors-20110929/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Using Scrapy selectors**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy is a Python web spider framework that is used to extract data from websites. It provides many powerful features for navigating entire websites, such as the ability to follow links. One feature it provides is the ability to find data within a document using the DOM, and using the now, quite familiar, XPath.\n",
    "\n",
    "In this recipe we will load the list of current questions on StackOverflow, and then parse this using a scrapy selector. Using that selector, we will extract the text of each question."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to do it**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing Selector from scrapy, and also requests so that we can retrieve the page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Selector xpath=None data='<html class=\"html__responsive \" lang=...'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scrapy.selector import Selector\n",
    "import requests\n",
    "# Next we load the page. For this example we are going to retrieve the most recent\n",
    "# questions on StackOverflow and extract their titles. We can make this query with the following:\n",
    "response = requests.get(\"https://stackoverflow.com/questions\")\n",
    "# Now create a Selector and pass it the response object:\n",
    "selector = Selector(response)\n",
    "selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='//div[@id=\"questions\"]/div/div[@class=\"s-post-summary--content\"]/div[@class=\"s-post-summary--content-excerpt\"]' data='<div class=\"s-post-summary--content-e...'>,\n",
       " <Selector xpath='//div[@id=\"questions\"]/div/div[@class=\"s-post-summary--content\"]/div[@class=\"s-post-summary--content-excerpt\"]' data='<div class=\"s-post-summary--content-e...'>,\n",
       " <Selector xpath='//div[@id=\"questions\"]/div/div[@class=\"s-post-summary--content\"]/div[@class=\"s-post-summary--content-excerpt\"]' data='<div class=\"s-post-summary--content-e...'>,\n",
       " <Selector xpath='//div[@id=\"questions\"]/div/div[@class=\"s-post-summary--content\"]/div[@class=\"s-post-summary--content-excerpt\"]' data='<div class=\"s-post-summary--content-e...'>,\n",
       " <Selector xpath='//div[@id=\"questions\"]/div/div[@class=\"s-post-summary--content\"]/div[@class=\"s-post-summary--content-excerpt\"]' data='<div class=\"s-post-summary--content-e...'>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With the selector we can find these using XPath:\n",
    "summaries = selector.xpath('//div[@id=\"questions\"]/div/div[@class=\"s-post-summary--content\"]/div[@class=\"s-post-summary--content-excerpt\"]')\n",
    "summaries[0:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we drill a little further into each to get the title of the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I was watching a yt tutorial and I can't seem to find the answer to this question.\\nI just want to margin top a button at 600px and the other at 500 px\\n<style>\\n   .subscribe-button{\\n      ...\",\n",
       " 'how to calculate the euclidean distance in a json file?\\ni have a error: no match for \\'operator+\\'\\n{\\n\"name\" : \"att5\",\\n\"comment\" : \"5 capitals of the US (Padberg/...',\n",
       " 'I have an expo project which I want to build an .aab app so that I can submit it on play store. But when I built it I get an error when it installs dependencies. I think the problem is one of the ...',\n",
       " \"I'm using Google Books API to get details about books using their ISBN numbers\\nISBN - International Standard Book Number is a numeric commercial book identifier that is intended to be unique\\nWhen ...\",\n",
       " 'I try to write some headers on a binary file, the rest of operation (bin file merging etc) are on a batch file but apparently batch is no good to write directly on binary files, i could not manage to ...',\n",
       " '2 images are unable to load\\nI restarted my app, there is no error at all, i suspect is storage?No errorsno errors in console either\\ncould there be something wrong with my package.json?\\nHere is my code:...',\n",
       " \"I want to create a mesh using the godot-rust API. I'm confused why calling Mesh::new() doesn't work but SurfaceTool::new() does.\\nThis is the error:\\nthe trait bound `Mesh: Instanciable` is not ...\",\n",
       " 'Has anyone tried to provide the ability to insert href hyper links in material ui text field?\\nimport TextField from \\'@mui/material/TextField\\';\\n  <TextField\\n    fullWidth\\n    label=\"Your ...',\n",
       " 'I want to use call() to create a call object. The value of one of the arguments is a data frame in the current environment. The name of that data frame object is stored as a string in a different ...',\n",
       " \"I'm trying to get all the console outputs from a stream that in this case, the stream is from a Python console. This is a part of a library that I'm doing on GitHub; in it you can find all the code.\\nI ...\"]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.strip() for x in summaries.xpath('text()').getall()][:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to do it**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underneath the covers, **Scrapy builds its selectors on top of lxml**. It offers a smaller and slightly simpler API, which is similar in performance to lxml."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **There's more**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about Scrapy Selectors see: https://doc.scrapy.org/en/latest/topics/selectors.html."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading data in unicode / UTF-8**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A document's encoding tells an application how the characters in the document are represented as bytes in the file. Essentially, the encoding specifies how many bits there are per character. In a standard ASCII document, all characters are 8 bits. HTML files are often encoded as 8 bits per character, but with the globalization of the internet, this is not always the case. Many HTML documents are encoded as 16-bit characters, or use a combination of 8- and 16-bit characters.\n",
    "\n",
    "A particularly common form HTML document encoding is referred to as UTF-8. This is the encoding form that we will examine."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Getting ready**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read a file named unicode.html from our local web server, located at http://localhost:8080/unicode.html.  This file is UTF-8 encoded and contains several sets of characters in different parts of the encoding space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to do it**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at using urlopen and requests to handle HTML in UTF-8. These two libraries handle this differently, so let's examine this.  Let's start importing urllib, loading the page, and examining some of the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'><strong>Cyrillic</strong> &nbsp; U+0400 \\xe2\\x80\\x93 U+04FF &nbsp; (1024\\xe2\\x80\\x931279)</p>\\n    <table class=\"unicode\">\\n        <tbody>\\n            <tr valign=\"top\">\\n                <td width=\"50\">&nbsp;</td>\\n                <td class=\"b\" width=\"50\">\\xd0\\x89</td>\\n                <td class=\"b\" width=\"50\">\\xd0\\xa9</td>\\n                <td class=\"b\" width=\"50\">\\xd1\\x89</td>\\n                <td class=\"b\" width=\"50\">\\xd3\\x83</td>\\n            </tr>\\n        </tbody>\\n    </table>\\n\\n '"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "page = urlopen(\"http://localhost:8080/unicode.html\")\n",
    "content = page.read()\n",
    "content[840:1280]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note how the Cyrillic characters were read in as multi-byte codes using \\ notation, such as `\\xd0\\x89`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<strong>Cyrillic</strong> &nbsp; U+0400 – U+04FF &nbsp; (1024–1279)</p>\\n    <table class=\"unicode\">\\n        <tbody>\\n            <tr valign=\"top\">\\n                <td width=\"50\">&nbsp;</td>\\n                <td class=\"b\" width=\"50\">Љ</td>\\n                <td class=\"b\" width=\"50\">Щ</td>\\n                <td class=\"b\" width=\"50\">щ</td>\\n                <td class=\"b\" width=\"50\">Ӄ</td>\\n            </tr>\\n        </tbody>\\n    </table>\\n\\n   '"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(content, \"utf-8\")[837:1270]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can exclude this extra step by using requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <p><strong>Cyrillic</strong> &nbsp; U+0400 â\\x80\\x93 U+04FF &nbsp; (1024â\\x80\\x931279)</p>\\n    <table class=\"unicode\">\\n        <tbody>\\n            <tr valign=\"top\">\\n                <td width=\"50\">&nbsp;</td>\\n                <td class=\"b\" width=\"50\">Ð\\x89</td>\\n                <td class=\"b\" width=\"50\">Ð©</td>\\n                <td class=\"b\" width=\"50\">Ñ\\x89</td>\\n                <td class=\"b\" width=\"50\">Ó\\x83</td>\\n            </tr>\\n        </tbody>\\n    <'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get(\"http://localhost:8080/unicode.html\")\n",
    "response.text[837:1270]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to works**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of using urlopen, the conversion was explicitly performed by using the str statement and specifying that the content should be converted to UTF-8. For requests, the library was able to determine from the content within the HTML that it was in UTF-8 format by seeing the following tag in the document:\n",
    "\n",
    "```HTML\n",
    "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **There's more**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of resources available on the internet for learning about Unicode and UTF-8 encoding techniques. Perhaps the best is the following Wikipedia article, which has an excellent summary and a great table describing the encoding technique: https://en.wikipedia.org/wiki/UTF-8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2e900357f7d7f0420973cc0a3db668cd1358155e01ada4ae7b047d426ff3a9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
